prp(fit2, type=4)
prp(fit2, type=3)
prp(fit2, type=3, extra=100)
prp(fit2, type=3, extra=1)
prp(fit2, type=3, extra=2)
prp(fit2, type=3, extra=3)
prp(fit2, type=3, extra=103)
prp(fit2, type=3, extra=104)
prp(fit2, type=3, extra=105)
prp(fit2, type=3, extra=106)
prp(fit2, type=3, extra=107)
prp(fit2, type=3, extra=108)
prp(fit2, type=3, extra=109)
prp(fit2, type=3, extra=104)
prp(fit2, type=3, extra=102)
prp(fit2, type=3, extra=104)
prp(fit2, type=3, extra=102)
prp(fit2, type=3, extra=101)
prp(fit2, type=3, extra=101)
prp(fit2, type=3, extra=101, snip=TRUE)
prp(fit2, type=3, extra=101, box.col=red)
prp(fit2, type=3, extra=101, box.col="red")
prp(fit2, type=3, extra=101)
prp(fit2, type=1, extra=101)
prp(fit2, type=3, extra=101)
prp(fit2, type=3, extra=102)
140 + 21 + 11 + 31 + 20
fit2 <- prune(fit, cp = 0.01)
# plot tree
prp(fit2, type=3, extra=102)
prp(fit1, type=3, extra=102)
prp(fit, type=3, extra=102)
custom_control = rpart.control(minsplit = 15, minbucket=5, cp = 0.005, maxdepth = 30)
prp(fit, type=3, extra=102)
custom_control = rpart.control(minsplit = 16, minbucket=8, cp = 0.005, maxdepth = 30)
prp(fit, type=3, extra=102)
# Prune tree
fit2 <- prune(fit, cp = 0.01)
# plot tree
prp(fit2, type=3, extra=102)
fit2 <- prune(fit, cp = 0.02)
# plot tree
prp(fit2, type=3, extra=102)
# Confusion matrix
fpreds = predict(fit2, newdata=cat_data, type="class")
ftable = table(actual=cat_data$Close, fpreds)
ftable
?prune
plotcp(fit) # visualize cross-validation results
resetPar <- function() {
dev.new()
op <- par(no.readonly = TRUE)
dev.off()
op
}
resetPar()
plotcp(fit) # visualize cross-validation results
resetPar <- function() {
dev.new()
op <- par(no.readonly = TRUE)
dev.off()
op
}
par(resetPar())
plotcp(fit) # visualize cross-validation results
prp(fit2, type=3, extra=102)
plotcp(fit) # visualize cross-validation results
############### Preprocessing ################
############### Preprocessing ################
# Open data.csv
raw_data <- read.csv("Data.csv")
# Discard "adj.close" --> Only selects those relevant columns
data <- raw_data[, c("Open", "High", "Low", "Close", "Volume")]
# Dicard row where Volume is NA
data <- data[complete.cases(data[,c("Volume")]),]
data_len <- nrow(data)
next_non_na <- function(data, col, min_idx) {
stopifnot(is.data.frame(data))
stopifnot(is.numeric(min_idx))
i = min_idx
data_len <- nrow(data)
while (i < data_len + 1) {
if (!is.na(data[i, col])) {
return(i)
}
i <- i + 1
}
return(-1) # not found
}
# Handle missing data
for (col in names(data)) {
# find first non-NA row
first_idx = next_non_na(data, col, 1)
if (first_idx > 1) {
# fill index 1 .. (first_idx - 1) with data[first_idx]
for (i in 1:(first_idx)) {
data[i, col] <- data[first_idx, col]
}
}
left = first_idx + 1
right = first_idx + 1
max_idx = first_idx
# middle
while (left < data_len + 1 && right > 0) {
left = next_non_na(data, col, right)
right = next_non_na(data, col, left + 1)
if (right > left + 1) {
# fill index (left + 1) .. (right - 1) with mean
mean_val <- mean(c(data[left, col], data[right, col]))
for (i in (left + 1):(right - 1)) {
data[i, col] <- mean_val
}
}
max_idx <- max(max_idx, right)
}
# fill in last data
if (max_idx < data_len) {
for (i in (max_idx + 1):(data_len)) {
data[i, col] <- data[max_idx, col]
}
}
}
# Difference data
diff_data <- data[-data_len,] # take all rows except the final row
for (col in names(data)) {
for (i in 1:(data_len - 1)) {
diff_data[i, col] <- data[i, col] / data[i + 1, col]
}
}
# Categorial data
cat_data <- diff_data
cats <- c("SU", "UP", "NC", "DN", "SD")
get_cat <- function(value, threshold1, threshold2) {
stopifnot(all(is.numeric(value), is.numeric(threshold1), is.numeric(threshold2), threshold1 > threshold2))
if (value > (1. + threshold1)) {
return(cats[1])
} else if (value > (1. + threshold2)) {
return(cats[2])
} else if (value > (1. - threshold2)) {
return(cats[3])
} else if (value > (1. - threshold1)) {
return(cats[4])
}
return(cats[5])
}
for (col in c("Open", "High", "Low", "Close")) {
for (i in 1:(data_len - 1)) {
cat_data[i, col] <- get_cat(diff_data[i, col], 0.015, 0.005)
}
}
# Volume
col = "Volume"
for (i in 1:(data_len - 1)) {
cat_data[i, col] <- get_cat(diff_data[i, col], 0.15, 0.05)
}
####### Grow Decision Tree ###########
# Target: Close
# Features: Open, High, Low, Volume
# Reading: http://scg.sdsu.edu/ctrees_r/
# Load library for decision tree
require('rpart')
require('rpart.plot') # for plotting the decision tree
# Parameters, TODO: TWEAK THIS
custom_control = rpart.control(minsplit = 16, minbucket=8, cp = 0.005, maxdepth = 30)
# Construct tree
fit <- rpart(Close ~ Open + High + Low + Volume, data=cat_data, method="class", control=custom_control)
printcp(fit) # display the results
plotcp(fit) # visualize cross-validation results
summary(fit) # detailed summary of splits
# plot tree
prp(fit, type=3, extra=102)
# Prune tree, TODO: TWEAK THIS TOO
fit2 <- prune(fit, cp = 0.02)
# plot tree
prp(fit2, type=3, extra=102)
# Confusion matrix
fpreds = predict(fit2, newdata=cat_data, type="class")
ftable = table(actual=cat_data$Close, fpreds)
ftable
12437
12437 - 245 - 1067
12437 - 245 - 1067 - 162
245 + 1067 + 162
install.packages("cvTools")
require('cvTools')
############### Preprocessing ################
# Open data.csv
raw_data <- read.csv("Data.csv")
# Discard "adj.close" --> Only selects those relevant columns
data <- raw_data[, c("Open", "High", "Low", "Close", "Volume")]
# Dicard row where Volume is NA
data <- data[complete.cases(data[,c("Volume")]),]
data_len <- nrow(data)
next_non_na <- function(data, col, min_idx) {
stopifnot(is.data.frame(data))
stopifnot(is.numeric(min_idx))
i = min_idx
data_len <- nrow(data)
while (i < data_len + 1) {
if (!is.na(data[i, col])) {
return(i)
}
i <- i + 1
}
return(-1) # not found
}
# Handle missing data
for (col in names(data)) {
# find first non-NA row
first_idx = next_non_na(data, col, 1)
if (first_idx > 1) {
# fill index 1 .. (first_idx - 1) with data[first_idx]
for (i in 1:(first_idx)) {
data[i, col] <- data[first_idx, col]
}
}
left = first_idx + 1
right = first_idx + 1
max_idx = first_idx
# middle
while (left < data_len + 1 && right > 0) {
left = next_non_na(data, col, right)
right = next_non_na(data, col, left + 1)
if (right > left + 1) {
# fill index (left + 1) .. (right - 1) with mean
mean_val <- mean(c(data[left, col], data[right, col]))
for (i in (left + 1):(right - 1)) {
data[i, col] <- mean_val
}
}
max_idx <- max(max_idx, right)
}
# fill in last data
if (max_idx < data_len) {
for (i in (max_idx + 1):(data_len)) {
data[i, col] <- data[max_idx, col]
}
}
}
# Difference data
diff_data <- data[-data_len,] # take all rows except the final row
for (col in names(data)) {
for (i in 1:(data_len - 1)) {
diff_data[i, col] <- data[i, col] / data[i + 1, col]
}
}
# Categorial data
cat_data <- diff_data
cats <- c("SU", "UP", "NC", "DN", "SD")
get_cat <- function(value, threshold1, threshold2) {
stopifnot(all(is.numeric(value), is.numeric(threshold1), is.numeric(threshold2), threshold1 > threshold2))
if (value > (1. + threshold1)) {
return(cats[1])
} else if (value > (1. + threshold2)) {
return(cats[2])
} else if (value > (1. - threshold2)) {
return(cats[3])
} else if (value > (1. - threshold1)) {
return(cats[4])
}
return(cats[5])
}
for (col in c("Open", "High", "Low", "Close")) {
for (i in 1:(data_len - 1)) {
cat_data[i, col] <- get_cat(diff_data[i, col], 0.015, 0.005)
}
}
# Volume
col = "Volume"
for (i in 1:(data_len - 1)) {
cat_data[i, col] <- get_cat(diff_data[i, col], 0.15, 0.05)
}
####### Grow Decision Tree ###########
# Target: Close
# Features: Open, High, Low, Volume
# Reading: http://scg.sdsu.edu/ctrees_r/
# Load library for decision tree
require('rpart')
require('rpart.plot') # for plotting the decision tree
# Load library for corss validation
require('cvTools')
# Parameters, TODO: TWEAK THIS
custom_control = rpart.control(minsplit = 16, minbucket=8, cp = 0.005, maxdepth = 30)
# Construct tree
fit <- rpart(Close ~ Open + High + Low + Volume, data=cat_data, method="class", control=custom_control)
cvFit(fit, data = cat_data, y = cat_data$Close, cost = rtmspe,
K = 5, R = 10, seed = 1234)
printcp(fit) # display the results
plotcp(fit) # visualize cross-validation results
summary(fit) # detailed summary of splits
# plot tree
prp(fit, type=3, extra=102)
# Prune tree, TODO: TWEAK THIS TOO
fit2 <- prune(fit, cp = 0.02)
# plot tree
prp(fit2, type=3, extra=102)
# Confusion matrix
fpreds = predict(fit2, newdata=cat_data, type="class")
ftable = table(actual=cat_data$Close, fpreds)
ftable
ccvFit(fit, data = cat_data, y = cat_data$Close, cost = rtmspe,
K = 5, R = 10, seed = 1234)
cvFit(fit, data = cat_data, y = cat_data$Close, cost = rtmspe,
K = 5, R = 10, seed = 1234)
cvFit(fit, data = cat_data, y = cat_data$Close,
K = 5, R = 10, seed = 1234)
cvFit(fit, data = cat_data, y = cat_data$Close, K = 5, R = 10, seed = 1234)
cvFit(fit, data = cat_data, y = cat_data$Close, K = 5, seed = 1234)
cvFit(fit, data = cat_data, formula = Close ~ Open + High + Low + Volume, K = 5, seed = 1234)
cvFit(fit, data = cat_data, y = Close, formula = Close ~ Open + High + Low + Volume, K = 5, seed = 1234)
cvFit(fit, data = cat_data, y = cat_data$Close, formula = Close ~ Open + High + Low + Volume, K = 5, seed = 1234)
cvFit(rpart, data = cat_data, formula = Close ~ Open + High + Low + Volume, K = 5, seed = 1234)
cvFit(rpart, data = cat_data, formula = Close ~ Open + High + Low + Volume, K = 5, seed = 1234, method="class", control=custom_control)
cvFit(rpart, data = cat_data, formula = Close ~ Open + High + Low + Volume, K = 5, seed = 1234, method="class", control=custom_control)
?cvTools
?cvFolds
cvFolds(20, K = 5, type = "random")
?cvFit
?cvSelect
############### Preprocessing ################
# Open data.csv
raw_data <- read.csv("Data.csv")
# Discard "adj.close" --> Only selects those relevant columns
data <- raw_data[, c("Open", "High", "Low", "Close", "Volume")]
# Dicard row where Volume is NA
data <- data[complete.cases(data[,c("Volume")]),]
data_len <- nrow(data)
next_non_na <- function(data, col, min_idx) {
stopifnot(is.data.frame(data))
stopifnot(is.numeric(min_idx))
i = min_idx
data_len <- nrow(data)
while (i < data_len + 1) {
if (!is.na(data[i, col])) {
return(i)
}
i <- i + 1
}
return(-1) # not found
}
# Handle missing data
for (col in names(data)) {
# find first non-NA row
first_idx = next_non_na(data, col, 1)
if (first_idx > 1) {
# fill index 1 .. (first_idx - 1) with data[first_idx]
for (i in 1:(first_idx)) {
data[i, col] <- data[first_idx, col]
}
}
left = first_idx + 1
right = first_idx + 1
max_idx = first_idx
# middle
while (left < data_len + 1 && right > 0) {
left = next_non_na(data, col, right)
right = next_non_na(data, col, left + 1)
if (right > left + 1) {
# fill index (left + 1) .. (right - 1) with mean
mean_val <- mean(c(data[left, col], data[right, col]))
for (i in (left + 1):(right - 1)) {
data[i, col] <- mean_val
}
}
max_idx <- max(max_idx, right)
}
# fill in last data
if (max_idx < data_len) {
for (i in (max_idx + 1):(data_len)) {
data[i, col] <- data[max_idx, col]
}
}
}
# Difference data
diff_data <- data[-data_len,] # take all rows except the final row
for (col in names(data)) {
for (i in 1:(data_len - 1)) {
diff_data[i, col] <- data[i, col] / data[i + 1, col]
}
}
# Categorial data
cat_data <- diff_data
cats <- c("SU", "UP", "NC", "DN", "SD")
get_cat <- function(value, threshold1, threshold2) {
stopifnot(all(is.numeric(value), is.numeric(threshold1), is.numeric(threshold2), threshold1 > threshold2))
if (value > (1. + threshold1)) {
return(cats[1])
} else if (value > (1. + threshold2)) {
return(cats[2])
} else if (value > (1. - threshold2)) {
return(cats[3])
} else if (value > (1. - threshold1)) {
return(cats[4])
}
return(cats[5])
}
for (col in c("Open", "High", "Low", "Close")) {
for (i in 1:(data_len - 1)) {
cat_data[i, col] <- get_cat(diff_data[i, col], 0.015, 0.005)
}
}
# Volume
col = "Volume"
for (i in 1:(data_len - 1)) {
cat_data[i, col] <- get_cat(diff_data[i, col], 0.15, 0.05)
}
####### Grow Decision Tree ###########
# Target: Close
# Features: Open, High, Low, Volume
# Reading: http://scg.sdsu.edu/ctrees_r/
# Load library for decision tree
require('rpart')
require('rpart.plot') # for plotting the decision tree
require('cvTools')
custom_control = rpart.control(minsplit = 16, minbucket=8, cp = 0.005, maxdepth = 30)
# Construct tree
fit <- rpart(Close ~ Open + High + Low + Volume, data=cat_data, method="class", control=custom_control)
cvFit(fit, data = cat_data, y = cat_data$Close, K = 5, R = 10, seed = 1234)
?cvTools
?cvFolds
cvFolds(data)
cvFolds(nrows(data))
cvFolds(nrow(cat_data))
cvFolds(nrow(cat_data), type="consecutive")
cvFolds(nrow(cat_data), type="interleaved")
cvFolds(nrow(cat_data))
folds <- cvFolds(nrow(cat_data))
folds
folds$Index
folds$subsets
folds$R
folds$which
cvFold
cvFolds
folds[1]
folds[2]
folds[3]
folds[4]
[folds$which = 1]
folds$subsets[folds$which = 1]
folds$subsets[folds$which == 1]
folds
folds$subsets[folds$which == 1]
1:5
cat_data[5]
cat_data
cat_data[][5]
cat_data[[5]]
cat_data[[,5]]
cat_data[,5
]
cat_data[5,5]
cat_data[5,]
cat_data[folds$subsets[folds$which == 1],]
nfolds <- 5
folds <- cvFolds(nrow(cat_data))
for (f in 1:nfolds) {
current_index <- folds$subsets[folds$which == f]
current_data <- cat_data[current_index,]
# Construct tree
fit <- rpart(Close ~ Open + High + Low + Volume, data=current_data, method="class", control=custom_control)
printcp(fit) # display the results
plotcp(fit) # visualize cross-validation results
summary(fit) # detailed summary of splits
}
cat_data[folds$subsets[folds$which == 1],]
# Construct tree
fit <- rpart(Close ~ Open + High + Low + Volume, data=cat_data, method="class", control=custom_control)
printcp(fit) # display the results
plotcp(fit) # visualize cross-validation results
summary(fit) # detailed summary of splits
# plot tree
prp(fit, type=3, extra=102)
# Prune tree, TODO: TWEAK THIS TOO
fit2 <- prune(fit, cp = 0.02)
# plot tree
prp(fit2, type=3, extra=102)
# Confusion matrix
fpreds = predict(fit2, newdata=cat_data, type="class")
ftable = table(actual=cat_data$Close, fpreds)
ftable
fit <- rpart(Close ~ Open + High + Low + Volume, data=cat_data, method="class", control=custom_control)
printcp(fit) # display the results
plotcp(fit) # visualize cross-validation results
summary(fit) # detailed summary of splits
# Confusion matrix
fpreds = predict(fit, newdata=cat_data, type="class")
ftable = table(actual=cat_data$Close, fpreds)
ftable
fit2 <- prune(fit, cp = 0.02)
# plot tree
prp(fit2, type=3, extra=102)
printcp(fit2) # display the results
plotcp(fit2) # visualize cross-validation results
summary(fit2) # detailed summary of splits
fit2 <- prune(fit, cp = 0.025)
# plot tree
prp(fit2, type=3, extra=102)
printcp(fit2) # display the results
plotcp(fit2) # visualize cross-validation results
summary(fit2) # detailed summary of splits
?prune
fit2 <- prune(fit, cp = 0.03)
# plot tree
prp(fit2, type=3, extra=102)
printcp(fit2) # display the results
plotcp(fit2) # visualize cross-validation results
summary(fit2) # detailed summary of splits
# Confusion matrix
fpreds = predict(fit2, newdata=cat_data, type="class")
ftable = table(actual=cat_data$Close, fpreds)
ftable
